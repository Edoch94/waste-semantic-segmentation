# @package _global_.model
train:
  stage:
    encoder:
      totrain: true
      pretrained: ''
    decoder:
      totrain: false

  input:
    batch_size: 16
    resume: '' # TODO it's a path

  learning_rate:
    lr: 0.0005 # 5e-4
    lr_decay: 0.995
    num_epoch_lr_decay: 1 # epochs
    weight_decay: 0.0002 # 2e-4
    label_weight: [1, 1] # torch.FloatTensor([1,1])
  num_workers: 12
  max_epoch: 20 #200

validation:
  input:
    batch_size: 12
    sample_rate: 1

  num_workers: 12
